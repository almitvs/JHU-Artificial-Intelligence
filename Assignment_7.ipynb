{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence\n",
    "# 464/664\n",
    "# Assignment #7\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Output format should be exactly as requested (it is your responsibility to make sure notebook looks as expected on Gradescope),\n",
    "02. Check submission deadline on Gradescope, \n",
    "03. Rename the file to Last_First_assignment_7, \n",
    "04. Submit your notebook (as .ipynb, not PDF) using Gradescope, and\n",
    "05. Do not submit any other files.\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "For this assignment we will explore Neural Networks; in particular, we are going to explore model complexity. We will use the same dataset from Assignment #6 to classify a mushroom as either edible ('e') or poisonous ('p'). You are free to use PyTorch, TensorFlow, scikit-learn -- to name a few resources. The goal is to explore different model complexities (architectures) before declaring a winner. Either start with a simple network and make it more complex; or start with a complex model and pare it down. Either way, your submission should clearly demonstrate your exploration. \n",
    "\n",
    "\n",
    "Your output for each model should look like the output of `cross_validate` from Assignment #6:\n",
    "\n",
    "```\n",
    "Fold: 0\tTrain Error: 15.38%\tValidation Error: 0.00%\n",
    "Fold: 1\n",
    "...\n",
    "\n",
    "Mean(Std. Dev.) over all folds:\n",
    "-------------------------------\n",
    "Train Error: 100.00%(0.00%) Test Error: 100.00%(0.00%)\n",
    "```\n",
    "\n",
    "Notice that \"Test Error\" has been replaced by \"Validation Error.\" Split your dataset into train, test, and validation sets. \n",
    "\n",
    "\n",
    "Start with a simple network. Train using the train set. Observe model's performance using the validation set. \n",
    "\n",
    "\n",
    "Increase the complexity of your network. Train using the train set. Observe model's performance using the validation set. \n",
    "\n",
    "\n",
    "Model complexity in Assignment #6 was depth limit. You can think of it here as the architecture of the network (number of layers and units per layer). Try at least three different network architectures. \n",
    "\n",
    "\n",
    "We're trying to find a model complexity that generalizes well. (Recall high bias vs high variance discussion in class.) \n",
    "\n",
    "\n",
    "Pick the network architecture that you deem best. Use the test set to report your winning model's performance. This is the ONLY time you use the test set.\n",
    "\n",
    "\n",
    "No other directions for this assignment, other than what's here and in the \"General Directions\" section. You have a lot of freedom with this assignment. Don't get carried away. Try at least three different models; more importantly, document your process. Graders are not going to run your notebooks. The notebook will be read as a report on how different models were explored: what the results were, how the winning model was determined, what was the winning model's performance on the test data. Clearly highlight these items to receive full credit. Since you'll be using libraries, the emphasis will be on your ability to communicate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Tuple, Callable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the functions from Assignment #6 will be borrowed to load the data, create the folds, and print the error rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_folds\"></a>\n",
    "## create_folds\n",
    "\n",
    "\n",
    "With n-fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. For data set with 100 observations (or records), n set to 10 would have 10 observations in each fold.\n",
    "\n",
    "* **data** List: a list (data_lecture, for instance)\n",
    "* **n** int: number of folds\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(data), n)\n",
    "    return list(data[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_train_test\"></a>\n",
    "## create_train_test\n",
    "\n",
    "\n",
    "This function takes the n folds and returns the train and test sets. One of the n folds is used to test, the others are used for training.\n",
    "\n",
    "* **folds** List[List[List]]: see `create_folds`\n",
    "* **index** int: fold index that is used for testing\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"parse_data\"></a>\n",
    "## parse_data\n",
    "\n",
    "Opens a file, splits on comma, and shuffles data before returning as a List of list. \n",
    "\n",
    "* **file_name** Str: filename for data\n",
    "\n",
    "\n",
    "**returns** \n",
    "Data as a list of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [ord(value) for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_stats\"></a>\n",
    "## get_stats\n",
    "\n",
    "This function computes the mean and the standard deviation for a given list of observations. \n",
    "\n",
    "* **observations** List[float]: A list of observations\n",
    "\n",
    "\n",
    "**returns** (mean, standard deviation) Tuple[float,float]: tuple consisting of mean and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(observations: List[float]) -> Tuple[float,float]:\n",
    "    mean = sum(observations) / len(observations)\n",
    "    variance = sum([(elem - mean)**2 for elem in observations]) / len(observations)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = parse_data(\"agaricus-lepiota.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = [record[1:]+[record[0]] for record in data_mushroom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names_mushroom = ['cap-shape',\n",
    "                   'cap-surface',\n",
    "                   'cap-color',\n",
    "                   'bruises?',\n",
    "                   'odor',\n",
    "                   'gill-attachment',\n",
    "                   'gill-spacing',\n",
    "                   'gill-size',\n",
    "                   'gill-color',\n",
    "                   'stalk-shape',\n",
    "                   'stalk-root',\n",
    "                   'stalk-surface-above-ring',\n",
    "                   'stalk-surface-below-ring',\n",
    "                   'stalk-color-above-ring',\n",
    "                   'stalk-color-below-ring',\n",
    "                   'veil-type',\n",
    "                   'veil-color',\n",
    "                   'ring-number',\n",
    "                   'ring-type',\n",
    "                   'spore-print-color',\n",
    "                   'population',\n",
    "                   'habitat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_mushroom = create_folds(data=data_mushroom, n=11)\n",
    "test_fold = copy.deepcopy(folds_mushroom[10])\n",
    "folds_mushroom = folds_mushroom[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created 3 different models. Each model is roughly similar but different in the number of hidden layers, the number of neurons per layer, and the total number of neurons. I decided to use ReLu, the rectified linear unit, because this is commonly used in binary classification problems. By varying that which I have described above in the modules, I hope to see which number of neurons and layers is more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: This model uses one layer of 6 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(nn.Module):\n",
    "    def __init__(self, input_features=22, layer_1=6, output_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, layer_1)\n",
    "        self.out = nn.Linear(layer_1, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: This model uses 2 layers of 6 and 3 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2(nn.Module):\n",
    "    def __init__(self, input_features=22, layer_1=6, layer_2=3, output_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, layer_1)\n",
    "        self.fc2 = nn.Linear(layer_1, layer_2)\n",
    "        self.out = nn.Linear(layer_2, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: The model uses 3 layers of 12, 6, and 3 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_3(nn.Module):\n",
    "    def __init__(self, input_features=22, layer_1=12, layer_2=6, layer_3=3, output_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, layer_1)\n",
    "        self.fc2 = nn.Linear(layer_1, layer_2)\n",
    "        self.fc3 = nn.Linear(layer_2, layer_3)\n",
    "        self.out = nn.Linear(layer_3, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_one = Model_1()\n",
    "m_two = Model_2()\n",
    "m_three = Model_3()\n",
    "models = [m_one, m_two, m_three]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(predicted, actual):\n",
    "    error = 0\n",
    "    for index in range(len(actual)):\n",
    "        pred = predicted.tolist()[index].index(max(predicted.tolist()[index]))\n",
    "        if (actual.tolist()[index][0] == 101):\n",
    "            act = 0\n",
    "        else:\n",
    "            act = 1\n",
    "        if (pred != act):\n",
    "            error += (1 / len(actual))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validate\"></a>\n",
    "## cross_validate\n",
    "\n",
    "This function tests each model with each fold of data. The models are trained on the training test and tested on the testing set. Backpropagation is used in the training process. Error rate is computed based on the number of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(folds, models):\n",
    "    for number, model in enumerate(models):\n",
    "        train_error, test_error  = [], []\n",
    "        error_list_train, error_list_test = [], []\n",
    "        for fold_index in range(len(folds)):\n",
    "            training_data, test_data = create_train_test(folds, fold_index)\n",
    "            train_X = copy.deepcopy(training_data)\n",
    "            train_y = copy.deepcopy(training_data)\n",
    "            train_X = [data[:-1] for data in train_X]\n",
    "            train_y = [[data[len(data) - 1]] for data in train_y]\n",
    "            \n",
    "            tr_X = torch.FloatTensor(train_X)\n",
    "            tr_y = torch.LongTensor(train_y)\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "            \n",
    "            train_y_hat = model.forward(tr_X)\n",
    "            loss = criterion(train_y_hat, torch.max(tr_y, 1)[1])         \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            test_X = copy.deepcopy(test_data)\n",
    "            test_y = copy.deepcopy(test_data)\n",
    "            test_X = [data[:-1] for data in test_X]\n",
    "            test_y = [[data[len(data) - 1]] for data in test_y]\n",
    "            \n",
    "            te_X = torch.FloatTensor(test_X)\n",
    "            te_y = torch.LongTensor(test_y)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                test_y_hat = model.forward(te_X) \n",
    "            \n",
    "            error_rate_train = get_error(train_y_hat, tr_y)\n",
    "            error_rate_test = get_error(test_y_hat, te_y)\n",
    "            error_list_train.append(error_rate_train)\n",
    "            error_list_test.append(error_rate_test)\n",
    "            print(f\"Fold: {fold_index}\\tTrain Error: {error_rate_train*100:.2f}%\\tValidation Error: {error_rate_test*100:.2f}%\")\n",
    "        print(f\"***\")\n",
    "        print(\"Model Number: \", number + 1)\n",
    "        print(f\"\\nMean(Std. Dev.) over all folds:\\n-------------------------------\")\n",
    "        print(f\"Train Error: {get_stats(error_list_train)[0]*100:.2f}%({get_stats(error_list_train)[1]*100:.2f}%) Validation Error: {get_stats(error_list_test)[0]*100:.2f}%({get_stats(error_list_test)[1]*100:.2f}%)\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    print(\"Testing the best model, model 2:\")\n",
    "    test_X = copy.deepcopy(test_fold)\n",
    "    test_y = copy.deepcopy(test_fold)\n",
    "    test_X = [data[:-1] for data in test_X]\n",
    "    test_y = [[data[len(data) - 1]] for data in test_y]\n",
    "            \n",
    "    te_X = torch.FloatTensor(test_X)\n",
    "    te_y = torch.LongTensor(test_y)\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        test_y_hat = m_one.forward(te_X) \n",
    "        \n",
    "    error_rate_test = get_error(test_y_hat, te_y)\n",
    "    print(f\"Error: {error_rate_test}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 48.70%\tValidation Error: 46.96%\n",
      "Fold: 1\tTrain Error: 48.31%\tValidation Error: 50.47%\n",
      "Fold: 2\tTrain Error: 48.77%\tValidation Error: 46.28%\n",
      "Fold: 3\tTrain Error: 48.32%\tValidation Error: 50.34%\n",
      "Fold: 4\tTrain Error: 48.77%\tValidation Error: 46.28%\n",
      "Fold: 5\tTrain Error: 48.35%\tValidation Error: 50.07%\n",
      "Fold: 6\tTrain Error: 48.57%\tValidation Error: 48.10%\n",
      "Fold: 7\tTrain Error: 48.42%\tValidation Error: 49.46%\n",
      "Fold: 8\tTrain Error: 48.27%\tValidation Error: 50.81%\n",
      "Fold: 9\tTrain Error: 48.75%\tValidation Error: 46.48%\n",
      "***\n",
      "Model Number:  1\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.52%(0.20%) Validation Error: 48.52%(1.80%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 48.73%\tValidation Error: 46.96%\n",
      "Fold: 1\tTrain Error: 48.31%\tValidation Error: 50.47%\n",
      "Fold: 2\tTrain Error: 48.77%\tValidation Error: 46.28%\n",
      "Fold: 3\tTrain Error: 48.32%\tValidation Error: 50.34%\n",
      "Fold: 4\tTrain Error: 48.77%\tValidation Error: 46.28%\n",
      "Fold: 5\tTrain Error: 48.35%\tValidation Error: 50.07%\n",
      "Fold: 6\tTrain Error: 48.57%\tValidation Error: 48.10%\n",
      "Fold: 7\tTrain Error: 48.42%\tValidation Error: 49.46%\n",
      "Fold: 8\tTrain Error: 48.27%\tValidation Error: 50.81%\n",
      "Fold: 9\tTrain Error: 48.75%\tValidation Error: 46.48%\n",
      "***\n",
      "Model Number:  2\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.53%(0.20%) Validation Error: 48.52%(1.80%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 51.30%\tValidation Error: 50.61%\n",
      "Fold: 1\tTrain Error: 50.34%\tValidation Error: 50.47%\n",
      "Fold: 2\tTrain Error: 48.77%\tValidation Error: 46.28%\n",
      "Fold: 3\tTrain Error: 48.32%\tValidation Error: 50.34%\n",
      "Fold: 4\tTrain Error: 48.77%\tValidation Error: 46.28%\n",
      "Fold: 5\tTrain Error: 48.35%\tValidation Error: 50.07%\n",
      "Fold: 6\tTrain Error: 48.57%\tValidation Error: 48.10%\n",
      "Fold: 7\tTrain Error: 48.42%\tValidation Error: 49.46%\n",
      "Fold: 8\tTrain Error: 48.27%\tValidation Error: 50.81%\n",
      "Fold: 9\tTrain Error: 48.75%\tValidation Error: 46.48%\n",
      "***\n",
      "Model Number:  3\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.99%(0.96%) Validation Error: 48.89%(1.82%)\n",
      "\n",
      "\n",
      "Testing the best model, model 2:\n",
      "Error: 0.4498644986449879%\n"
     ]
    }
   ],
   "source": [
    "cross_validate(folds_mushroom, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation and Exploration:\n",
    "\n",
    "First, I created 3 models which use rectified linear unit to form a neural network. I decided to add another layer to each module, and to have to number of neurons in each lay half from start to finish, ending in 3. I did some research on line and found that decreasing the number of neurons after each layer is best practice as it narrows towards the output. Thus, the total number of layers, as well as the total number of neurons varied. I read that the total number of neuron should be close to the number of traits which are being trained on to classify, so I predicted that the third model should work the best.\n",
    "\n",
    "Next, the data was split into folds, and folds were split into training and validation sets. For each fold, each model was trainined then tested with the validation set. Originally, I also used backpropagation during the training, but this caused overfitting, despite not making too much of an impact.\n",
    "\n",
    "Overall the models did not work very differently, or very well! All of the models are very prone to underfitting. The models did not fit the training data very well, only guessing right roughly half the time, and so did not learn the patterns properly and also performed poorly on validation data.\n",
    "\n",
    "The first model performed the best by a marginal amount. Clearly, the extra layers and neurons were not necessary. Too many neurons in a layer can lead to overfitting, which did not happen. The extra layers may not have been necessary with the number of classes and outputs. Underfitting is usually caused by low variance and high bias.\n",
    "\n",
    "How could this be fixed? Perhaps more training time. Data size does not seem to be the issue. The biggest problem could be the use of the linear unit itself. A non-linear approach may be beneficial for this type of data. The tree approach worked very well on this data in the last assignment. The ReLu model is too simplistic and does not capture the underlying relationships in the data.\n",
    "\n",
    "Nevertheless, the first model worked relatively better. I chose it because it had the lowest average error rate. Still, this error rate was on average about 48%! There is a typo in the output, it should say \"Testing the best model, model 1:\". Surprisingly, its performance on the fold saved for the final test was the best out of all folds, coming in at 44%. The fact that there are only 2 categories and the model is only right half the time shows the poor fitting.\n",
    "\n",
    "In conclusion, varying the number of layers and the number of neurons does not always make a large impact, especially when the model itself is not adequate for the data. After testing these three models, in addition to testing countless other layer and neuron combinations in the process, I have see that the key to better fitting can be to find a model that better fits the type of data on which one is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
